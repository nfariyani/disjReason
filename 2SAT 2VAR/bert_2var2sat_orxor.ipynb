{"cells":[{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3359,"status":"ok","timestamp":1647952163031,"user":{"displayName":"Nurul Ariyani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvEAOiffSleor2Ddf_32vbJoE2vtwPjqtx9PdAjg=s64","userId":"15069198330605328757"},"user_tz":0},"id":"AeSDv1RMjat_","outputId":"661569df-b6e5-4962-9434-17d8106c3d47"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3219,"status":"ok","timestamp":1647952168559,"user":{"displayName":"Nurul Ariyani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvEAOiffSleor2Ddf_32vbJoE2vtwPjqtx9PdAjg=s64","userId":"15069198330605328757"},"user_tz":0},"id":"RlZ3f_kpjKOU","outputId":"c7501acd-3251-4d78-eaf1-c7ff9fc27ffe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.0.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.2.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n","Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.63.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"]}],"source":["!pip install datasets"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3305,"status":"ok","timestamp":1647952174907,"user":{"displayName":"Nurul Ariyani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvEAOiffSleor2Ddf_32vbJoE2vtwPjqtx9PdAjg=s64","userId":"15069198330605328757"},"user_tz":0},"id":"yOp0mr78j3KF","outputId":"b949a302-979e-4119-f532-fa04d995fbf8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (0.4.4)\n"]}],"source":["!pip install colorama"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"wJY98AQehzay","executionInfo":{"status":"ok","timestamp":1647952175216,"user_tz":0,"elapsed":4,"user":{"displayName":"Nurul Ariyani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvEAOiffSleor2Ddf_32vbJoE2vtwPjqtx9PdAjg=s64","userId":"15069198330605328757"}}},"outputs":[],"source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","import sys\n","import torch\n","from datasets import load_dataset\n","from datasets import Dataset\n","import numpy as np\n","from torch.utils.data import RandomSampler, DataLoader, SequentialSampler, TensorDataset\n","from tqdm import tqdm\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from colorama import Fore\n","\n","import re\n","\n","#Removed special symbols that were not captured by punctuation\n","def remove_special_symbols(text):\n","    text = re.sub('->', ' ', str(text))\n","    text = re.sub('“', ' ', str(text))\n","    text = re.sub('”', ' ', str(text))\n","    text = re.sub('\\.',' ', str(text))\n","    return re.sub('’',' ', str(text))\n","  \n","def denoise_text(text):\n","    text = remove_special_symbols(text)\n","    return str(text)\n","\n","#Convert labels to numbers\n","def convert_labels(text):\n","  if(text == 'neutral'):\n","    text = 0\n","  elif (text=='entailment'):\n","    text = 1\n","  elif (text=='contradiction'):\n","    text = 2\n","  return text"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1646,"status":"ok","timestamp":1647952181666,"user":{"displayName":"Nurul Ariyani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvEAOiffSleor2Ddf_32vbJoE2vtwPjqtx9PdAjg=s64","userId":"15069198330605328757"},"user_tz":0},"id":"mFIs8F1SPEDC","outputId":"ca89b99d-2c95-43a7-d9d8-0de1b4e3c5e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3204,"status":"ok","timestamp":1647952206248,"user":{"displayName":"Nurul Ariyani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvEAOiffSleor2Ddf_32vbJoE2vtwPjqtx9PdAjg=s64","userId":"15069198330605328757"},"user_tz":0},"id":"RNqCWxbiDPoB","outputId":"1505d593-8d01-40a8-b4a8-9af6c3b9bda0"},"outputs":[{"output_type":"stream","name":"stdout","text":["10000\n","1000\n"]}],"source":["gpu = torch.device('cuda')\n","# ============================================= DOWNLOADING DATA =======================================================\n","epochs = 3\n","batch_size = 8\n","max_seq_length = 128\n","\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","import pandas as pd\n","pd.options.mode.chained_assignment = None\n","\n","df_train = pd.read_csv('gdrive/MyDrive/Colab Notebooks/2sat2var/small_10K/train_data_10K.csv', sep=None, engine=\"python\")\n","df_eval = pd.read_csv('gdrive/MyDrive/Colab Notebooks/2sat2var/small_10K/eval_data_10K.csv', sep=None, engine=\"python\")\n","\n","print(len(df_train))\n","print(len(df_eval))\n","\n","train_data = Dataset.from_pandas(df_train)\n","eval_data = Dataset.from_pandas(df_eval)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":312,"status":"ok","timestamp":1647882191385,"user":{"displayName":"Nurul Ariyani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvEAOiffSleor2Ddf_32vbJoE2vtwPjqtx9PdAjg=s64","userId":"15069198330605328757"},"user_tz":0},"id":"mM7t3AHX33h_","outputId":"dae23980-41e9-48f5-e197-ea7b52138749"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'idx': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n"," 'is_inclusive': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n"," 'label': [1, 0, 1, 1, 0, 1, 1, 0, 1, 0],\n"," 'premise': ['Rogers is snobby or Enos is not logical. Rogers is snobby.',\n","  'Rogers is snobby or Enos is not logical. Rogers is snobby.',\n","  'Rogers is snobby or Enos is not logical. Rogers is snobby.',\n","  'Rogers is snobby or Enos is not logical. Rogers is snobby.',\n","  'Quinten is not childlike or Mary is not cranky. Mary is cranky.',\n","  'Quinten is not childlike or Mary is not cranky. Mary is cranky.',\n","  'Quinten is not childlike or Mary is not cranky. Mary is cranky.',\n","  'Quinten is not childlike or Mary is not cranky. Mary is cranky.',\n","  'Either Claudette is not leery or Harvie is not musical. Claudette is leery.',\n","  'Either Claudette is not leery or Harvie is not musical. Claudette is leery.'],\n"," 'question': ['Rogers is snobby',\n","  'Rogers is not snobby',\n","  'Enos is logical',\n","  'Enos is not logical',\n","  'Quinten is childlike',\n","  'Quinten is not childlike',\n","  'Mary is cranky',\n","  'Mary is not cranky',\n","  'Claudette is leery',\n","  'Claudette is not leery']}"]},"metadata":{},"execution_count":10}],"source":["train_data[:10]"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"4GDHumYdh3Fv","executionInfo":{"status":"ok","timestamp":1647952213586,"user_tz":0,"elapsed":289,"user":{"displayName":"Nurul Ariyani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvEAOiffSleor2Ddf_32vbJoE2vtwPjqtx9PdAjg=s64","userId":"15069198330605328757"}}},"outputs":[],"source":["# ============================================= PREPARING DATASET ======================================================\n","\n","\n","def truncate_seq_pair(tokens_a, tokens_b, max_length):\n","    while True:\n","        total_length = len(tokens_a) + len(tokens_b)\n","        if total_length <= max_length:\n","            break\n","        if len(tokens_a) > len(tokens_b): #trim the longest token\n","            tokens_a.pop()\n","        else:\n","            tokens_b.pop()\n","\n","\n","def convert_examples_to_features(examples, desc):\n","    p_bar = tqdm(total=len(examples), desc=desc,\n","                 position=0, leave=True,\n","                 file=sys.stdout, bar_format=\"{l_bar}%s{bar}%s{r_bar}\" % (Fore.BLUE, Fore.RESET))\n","    labels = []\n","    input_word_ids = []\n","    input_type_ids = []\n","    input_masks = []\n","    for (index, example) in enumerate(examples):\n","        if \"label\" in example:\n","            labels.append(example[\"label\"])\n","        example[\"premise\"]=denoise_text(example[\"premise\"])\n","        example[\"question\"]=denoise_text(example[\"question\"])\n","        tokens_a = tokenizer.tokenize(example[\"premise\"])\n","        tokens_b = tokenizer.tokenize(example[\"question\"])\n","        truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n","        tokens = []\n","        segment_ids = []\n","        #Inserting tokens for sentence1\n","        tokens.append(\"[CLS]\")\n","        segment_ids.append(0)\n","        for token in tokens_a:\n","            tokens.append(token)\n","            segment_ids.append(0)\n","        tokens.append(\"[SEP]\")\n","        segment_ids.append(0)\n","        #Inserting tokens for sentence2\n","        for token in tokens_b:\n","            tokens.append(token)\n","            segment_ids.append(1)\n","        tokens.append(\"[SEP]\")\n","        segment_ids.append(1)\n","        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","        input_mask = [1] * len(input_ids)\n","        #Padding the input_mask\n","        while len(input_ids) < max_seq_length:\n","            input_ids.append(0)\n","            input_mask.append(0)\n","            segment_ids.append(0)\n","        input_word_ids.append(input_ids)\n","        input_type_ids.append(segment_ids)\n","        input_masks.append(input_mask)\n","        p_bar.update(1)\n","    p_bar.close()\n","    return [torch.tensor(input_word_ids, dtype=torch.int64),\n","            torch.tensor(input_masks, dtype=torch.float),\n","            torch.tensor(input_type_ids, dtype=torch.int64),\n","            torch.tensor(labels, dtype=torch.int64)]\n"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9647,"status":"ok","timestamp":1647952226869,"user":{"displayName":"Nurul Ariyani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvEAOiffSleor2Ddf_32vbJoE2vtwPjqtx9PdAjg=s64","userId":"15069198330605328757"},"user_tz":0},"id":"C8ruoH9tlH-p","outputId":"609473e6-5d73-46fc-984c-e8830bea0855"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating training samples: 100%|\u001b[34m██████████\u001b[39m| 10000/10000 [00:08<00:00, 1218.49it/s]\n","Creating evaluation samples: 100%|\u001b[34m██████████\u001b[39m| 1000/1000 [00:00<00:00, 1047.27it/s]\n"]}],"source":["train_data = TensorDataset(*convert_examples_to_features(train_data, \"Creating training samples\"))\n","train_sampler = RandomSampler(train_data)\n","train_data_loader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","eval_data = TensorDataset(*convert_examples_to_features(eval_data, \"Creating evaluation samples\"))\n","eval_sampler = SequentialSampler(eval_data)\n","validation_data_loader = DataLoader(eval_data, sampler=eval_sampler, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":347,"status":"ok","timestamp":1647882312851,"user":{"displayName":"Nurul Ariyani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvEAOiffSleor2Ddf_32vbJoE2vtwPjqtx9PdAjg=s64","userId":"15069198330605328757"},"user_tz":0},"id":"sl36vJAKUmWi","outputId":"996862f8-7541-4b7f-f836-07c5e4947e26"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[  101,  7369,  2003,  ...,     0,     0,     0],\n","         [  101,  7369,  2003,  ...,     0,     0,     0],\n","         [  101,  7369,  2003,  ...,     0,     0,     0],\n","         ...,\n","         [  101,  2593, 14304,  ...,     0,     0,     0],\n","         [  101,  2593, 14304,  ...,     0,     0,     0],\n","         [  101,  2593, 14304,  ...,     0,     0,     0]]),\n"," tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n","         [1., 1., 1.,  ..., 0., 0., 0.],\n","         [1., 1., 1.,  ..., 0., 0., 0.],\n","         ...,\n","         [1., 1., 1.,  ..., 0., 0., 0.],\n","         [1., 1., 1.,  ..., 0., 0., 0.],\n","         [1., 1., 1.,  ..., 0., 0., 0.]]),\n"," tensor([[0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]]),\n"," tensor([1, 0, 1,  ..., 0, 1, 1]))"]},"metadata":{},"execution_count":13}],"source":["train_data.tensors"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2574,"status":"ok","timestamp":1647952240859,"user":{"displayName":"Nurul Ariyani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvEAOiffSleor2Ddf_32vbJoE2vtwPjqtx9PdAjg=s64","userId":"15069198330605328757"},"user_tz":0},"id":"BOY3A4bJkhMi","outputId":"af35611c-4722-4afc-d1fb-667a2d435091"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# ================================================ TRAINING MODEL ======================================================\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2).to(device=gpu)\n","\n","param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'gamma', 'beta']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}\n","]\n","\n","optimizer = torch.optim.Adam(lr=1e-5, betas=(0.9, 0.98), eps=1e-9, params=optimizer_grouped_parameters)\n","# model.load_state_dict(torch.load(\"./weights_4.pth\"))\n"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rszwb37noEEO","executionInfo":{"status":"ok","timestamp":1647954075488,"user_tz":0,"elapsed":1796037,"user":{"displayName":"Nurul Ariyani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvEAOiffSleor2Ddf_32vbJoE2vtwPjqtx9PdAjg=s64","userId":"15069198330605328757"}},"outputId":"f5ee33c4-23af-477a-f546-3e7b94ebb8b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training epoch  1\n","  6%|\u001b[32m▌         \u001b[39m| 608/10000 [00:26<06:53, 22.72it/s]\n","100%|\u001b[32m██████████\u001b[39m| 10000/10000 [02:55<00:00, 56.97it/s]\n","\n","Training loss=0.4680\n","100%|\u001b[34m██████████\u001b[39m| 1000/1000 [00:04<00:00, 226.83it/s]\n","Validation Accuracy: 0.919\n","Training epoch  2\n","100%|\u001b[32m██████████\u001b[39m| 10000/10000 [02:54<00:00, 57.23it/s]\n","\n","Training loss=0.0855\n","100%|\u001b[34m██████████\u001b[39m| 1000/1000 [00:04<00:00, 225.61it/s]\n","Validation Accuracy: 0.996\n","Training epoch  3\n","100%|\u001b[32m██████████\u001b[39m| 10000/10000 [02:55<00:00, 57.04it/s]\n","\n","Training loss=0.0232\n","100%|\u001b[34m██████████\u001b[39m| 1000/1000 [00:04<00:00, 226.57it/s]\n","Validation Accuracy: 0.996\n","Training epoch  4\n","100%|\u001b[32m██████████\u001b[39m| 10000/10000 [02:54<00:00, 57.19it/s]\n","\n","Training loss=0.0136\n","100%|\u001b[34m██████████\u001b[39m| 1000/1000 [00:04<00:00, 225.79it/s]\n","Validation Accuracy: 0.996\n","Training epoch  5\n","100%|\u001b[32m██████████\u001b[39m| 10000/10000 [02:54<00:00, 57.30it/s]\n","\n","Training loss=0.0108\n","100%|\u001b[34m██████████\u001b[39m| 1000/1000 [00:04<00:00, 228.10it/s]\n","Validation Accuracy: 1.0\n","Training epoch  6\n","100%|\u001b[32m██████████\u001b[39m| 10000/10000 [02:54<00:00, 57.40it/s]\n","\n","Training loss=0.0073\n","100%|\u001b[34m██████████\u001b[39m| 1000/1000 [00:04<00:00, 226.44it/s]\n","Validation Accuracy: 0.997\n","Training epoch  7\n","100%|\u001b[32m██████████\u001b[39m| 10000/10000 [02:54<00:00, 57.34it/s]\n","\n","Training loss=0.0050\n","100%|\u001b[34m██████████\u001b[39m| 1000/1000 [00:04<00:00, 226.62it/s]\n","Validation Accuracy: 0.999\n","Training epoch  8\n","100%|\u001b[32m██████████\u001b[39m| 10000/10000 [02:53<00:00, 57.61it/s]\n","\n","Training loss=0.0086\n","100%|\u001b[34m██████████\u001b[39m| 1000/1000 [00:04<00:00, 228.88it/s]\n","Validation Accuracy: 0.998\n","Training epoch  9\n","100%|\u001b[32m██████████\u001b[39m| 10000/10000 [02:53<00:00, 57.55it/s]\n","\n","Training loss=0.0033\n","100%|\u001b[34m██████████\u001b[39m| 1000/1000 [00:04<00:00, 227.80it/s]\n","Validation Accuracy: 0.999\n","Training epoch  10\n","100%|\u001b[32m██████████\u001b[39m| 10000/10000 [02:53<00:00, 57.59it/s]\n","\n","Training loss=0.0039\n","100%|\u001b[34m██████████\u001b[39m| 1000/1000 [00:04<00:00, 228.33it/s]\n","Validation Accuracy: 0.999\n"]}],"source":["epochs = 10\n","for epoch in range(1, epochs + 1):\n","    # ============================================ TRAINING ============================================================\n","    print(\"Training epoch \", str(epoch))\n","    training_pbar = tqdm(total=len(train_data),\n","                         position=0, leave=True,\n","                         file=sys.stdout, bar_format=\"{l_bar}%s{bar}%s{r_bar}\" % (Fore.GREEN, Fore.RESET))\n","    model.train()\n","    tr_loss = 0\n","    nb_tr_steps = 0\n","    for step, batch in enumerate(train_data_loader):\n","        batch = tuple(t.to(gpu) for t in batch)\n","        input_word_ids, input_mask, input_type_ids, labels = batch\n","        optimizer.zero_grad() #clear gradient first\n","        loss, _ = model(input_ids=input_word_ids,\n","                        attention_mask=input_mask,\n","                        token_type_ids=input_type_ids,\n","                        labels=labels, return_dict=False)\n","        loss.backward()\n","        optimizer.step()\n","        tr_loss += loss.item()\n","        nb_tr_steps += 1\n","        training_pbar.update(input_word_ids.size(0))\n","    training_pbar.close()\n","    print(f\"\\nTraining loss={tr_loss / nb_tr_steps:.4f}\")\n","    torch.save(model.state_dict(), \"./small_weights_\" + str(epoch) + \".pth\")\n","    \n","    # ============================================ VALIDATION ==========================================================\n","    validation_pbar = tqdm(total=len(eval_data),\n","                           position=0, leave=True,\n","                           file=sys.stdout, bar_format=\"{l_bar}%s{bar}%s{r_bar}\" % (Fore.BLUE, Fore.RESET))\n","    model.eval()\n","    eval_accuracy = 0\n","    nb_eval_steps = 0\n","    for batch in validation_data_loader:\n","        batch = tuple(t.to(gpu) for t in batch)\n","        input_word_ids, input_mask, input_type_ids, labels = batch\n","        with torch.no_grad():\n","            logits = model(input_ids=input_word_ids,\n","                           attention_mask=input_mask,\n","                           token_type_ids=input_type_ids, return_dict=False)\n","\n","        logits = logits[0].detach().cpu().numpy()\n","        label_ids = labels.cpu().numpy()\n","        pred_flat = np.argmax(logits, axis=1).flatten()\n","        labels_flat = label_ids.flatten()\n","        eval_accuracy += np.sum(pred_flat == labels_flat) / len(labels_flat)\n","        nb_eval_steps += 1\n","        validation_pbar.update(input_word_ids.size(0))\n","    validation_pbar.close()\n","    print(\"Validation Accuracy: {}\".format(eval_accuracy / nb_eval_steps))\n"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":271,"status":"ok","timestamp":1647954541952,"user":{"displayName":"Nurul Ariyani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvEAOiffSleor2Ddf_32vbJoE2vtwPjqtx9PdAjg=s64","userId":"15069198330605328757"},"user_tz":0},"id":"nAS2cV9UoOD7","outputId":"a52af90b-f302-46f7-bb70-c4da6cd4cf57"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating test samples: 100%|\u001b[34m██████████\u001b[39m| 2/2 [00:00<00:00, 1409.14it/s]\n","[[-6.113086   6.5828385]\n"," [ 3.4487603 -4.2878833]]\n","{'premise': 'Either Charlie is smart or Ron is lazy  Ron is not lazy', 'question': 'Charlie is smart '}\n","{'premise': 'Either I am going to the party or I am going to the gym  I am going to the gym ', 'question': 'I am not going to the party '}\n","[1 0]\n"]}],"source":["# ============================================ TESTING =================================================================\n","#model.load_state_dict(torch.load(\"gdrive/MyDrive/Colab Notebooks/2sat2var/weights_3.pth\"))\n","model.eval()\n","test_data = [{\n","        'premise': 'Either Charlie is smart or Ron is lazy. Ron is not lazy',\n","        'question': 'Charlie is smart.'\n","    }, {\n","        'premise': 'Either I am going to the party or I am going to the gym. I am going to the gym.',\n","        'question': 'I am not going to the party.'\n","    }]\n","input_word_ids_test, input_masks_test, input_type_ids_test, _ = convert_examples_to_features(test_data, \"Creating test samples\")\n","result = model(input_ids=input_word_ids_test.to(gpu),\n","               attention_mask=input_masks_test.to(gpu),\n","               token_type_ids=input_type_ids_test.to(gpu), return_dict=False)\n","result = result[0].detach().cpu()\n","print(result.numpy())\n","result = torch.argmax(result, dim=1).numpy()\n","print(test_data[0])\n","print(test_data[1])\n","print(result)\n"]},{"cell_type":"code","source":["# ============================================ TESTING =================================================================\n","#model.load_state_dict(torch.load(\"gdrive/MyDrive/Colab Notebooks/2sat2var/weights_3.pth\"))\n","model.load_state_dict(torch.load(\"small_weights_9.pth\"))\n","\n","df_test = pd.read_csv('gdrive/MyDrive/Colab Notebooks/2sat2var/medium_100K/test_data_100K.csv', sep=None, engine=\"python\")\n","test_data = Dataset.from_pandas(df_test)\n","\n","test_data = TensorDataset(*convert_examples_to_features(test_data, \"Creating test samples\"))\n","test_sampler = SequentialSampler(test_data)\n","test_data_loader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n","\n","#print(len(test_data))\n","\n","test_pbar = tqdm(total=len(test_data),\n","                           position=0, leave=True,\n","                           file=sys.stdout, bar_format=\"{l_bar}%s{bar}%s{r_bar}\" % (Fore.RED, Fore.RESET))\n","\n","model.eval()\n","test_accuracy = 0\n","nb_test_steps = 0\n","for batch in test_data_loader:\n","  batch = tuple(t.to(gpu) for t in batch)\n","  input_word_ids, input_mask, input_type_ids, labels = batch\n","  with torch.no_grad():\n","    result = model(input_ids=input_word_ids,\n","                           attention_mask=input_mask,\n","                           token_type_ids=input_type_ids, return_dict=False)\n","\n","    result = result[0].detach().cpu().numpy()\n","    label_ids = labels.cpu().numpy()\n","    pred_flat = np.argmax(result, axis=1).flatten()\n","    labels_flat = label_ids.flatten()\n","    test_accuracy += np.sum(pred_flat == labels_flat) / len(labels_flat)\n","    nb_test_steps += 1\n","    test_pbar.update(input_word_ids.size(0))\n","test_pbar.close()\n","print(\"Test Accuracy: {}\".format(test_accuracy / nb_test_steps))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"posbtvMaDJW0","executionInfo":{"status":"ok","timestamp":1647954619212,"user_tz":0,"elapsed":54463,"user":{"displayName":"Nurul Ariyani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvEAOiffSleor2Ddf_32vbJoE2vtwPjqtx9PdAjg=s64","userId":"15069198330605328757"}},"outputId":"a1a044cf-7145-4cbf-cd7e-f77818580d1f"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating test samples: 100%|\u001b[34m██████████\u001b[39m| 10000/10000 [00:09<00:00, 1107.94it/s]\n","100%|\u001b[31m██████████\u001b[39m| 10000/10000 [00:44<00:00, 224.27it/s]\n","Test Accuracy: 0.9982\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"B1dbY89mZkxN"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"bert_2var2sat_orxor.ipynb","provenance":[{"file_id":"1jXeVvasuTH2bI2la38QH7AqA15u9N1Ko","timestamp":1647299906083}],"mount_file_id":"1raiI1IdMtDVyCflrFYpvCBHOtmsdH8FB","authorship_tag":"ABX9TyMOVU+mWGPiF5rFP1ugURjK"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}